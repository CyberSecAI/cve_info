{
    "cveId": "CVE-2025-48942",
    "version": "1.0.0",
    "timestamp": "2025-07-04T16:12:41.853043+00:00",
    "description": "vLLM is an inference and serving engine for large language models (LLMs). In versions 0.8.0 up to but excluding 0.9.0, hitting the /v1/completions API with a invalid json_schema as a Guided Param kills the vllm server. This vulnerability is similar GHSA-9hcf-v7m4-6m2j/CVE-2025-48943, but for regex instead of a JSON schema. Version 0.9.0 fixes the issue.",
    "keyphrases": {
        "rootcause": "",
        "weakness": "invalid json_schema",
        "impact": "kill the vllm server",
        "vector": "",
        "attacker": "",
        "product": "vLLM",
        "version": "0.8.0 up to but excluding 0.9.0",
        "component": "/v1/completions API"
    }
}
