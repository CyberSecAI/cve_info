{
    "cveId": "CVE-2025-22015",
    "version": "1.0.0",
    "timestamp": "2025-07-04T16:12:41.853043+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved mm/migrate fix shmem xarray update during migration A shmem folio can be either in page cache or in swap cache, but not at the same time. Namely, once it is in swap cache, folio->mapping should be NULL, and the folio is no longer in a shmem mapping. In __folio_migrate_mapping(), to determine the number of xarray entries to update, folio_test_swapbacked() is used, but that conflates shmem in page cache case and shmem in swap cache case. It leads to xarray multi-index entry corruption, since it turns a sibling entry to a normal entry during xas_store() (see [1] for a userspace reproduction). Fix it by only using folio_test_swapcache() to determine whether xarray is storing swap cache entries or not to choose the right number of xarray entries to update. [1] https//lore.kernel.org/linux-mm/Z8idPCkaJW1IChjT@casper.infradead.org/ Note In __split_huge_page(), folio_test_anon() && folio_test_swapcache() is used to get swap_cache address space, but that ignores the shmem folio in swap cache case. It could lead to NULL pointer dereferencing when a in-swap-cache shmem folio is split at __xa_store(), since !folio_test_anon() is true and folio->mapping is NULL. But fortunately, its caller split_huge_page_to_list_to_order() bails out early with EBUSY when folio->mapping is NULL. So no need to take care of it here.",
    "keyphrases": {
        "rootcause": "conflates shmem in page cache case and shmem in swap cache case",
        "weakness": "xarray multi-index entry corruption",
        "impact": "NULL pointer dereferencing",
        "vector": "",
        "attacker": "",
        "product": "Linux kernel",
        "version": "",
        "component": "mm/migrate fix shmem xarray update during migration"
    }
}
