{
    "cveId": "CVE-2025-21939",
    "version": "1.0.0",
    "timestamp": "2025-07-04T16:12:41.853043+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved drm/xe/hmm Dont dereference struct page pointers without notifier lock The pnfs that we obtain from hmm_range_fault() point to pages that we dont have a reference on, and the guarantee that they are still in the cpu page-tables is that the notifier lock must be held and the notifier seqno is still valid. So while building the sg table and marking the pages accesses / dirty we need to hold this lock with a validated seqno. However, the lock is reclaim tainted which makes sg_alloc_table_from_pages_segment() unusable, since it internally allocates memory. Instead build the sg-table manually. For the non-iommu case this might lead to fewer coalesces, but if thats a problem it can be fixed up later in the resource cursor code. For the iommu case, the whole sg-table may still be coalesced to a single contigous device va region. This avoids marking pages that we dont own dirty and accessed, and it also avoid dereferencing struct pages that we dont own. v2 - Use assert to check whether hmm pfns are valid (Matthew Auld) - Take into account that large pages may cross range boundaries (Matthew Auld) v3 - Dont unnecessarily check for a non-freed sg-table. (Matthew Auld) - Add a missing up_read() in an error path. (Matthew Auld) (cherry picked from commit ea3e66d280ce2576664a862693d1da8fd324c317)",
    "keyphrases": {
        "rootcause": "",
        "weakness": "dereference struct page pointers without notifier lock",
        "impact": "",
        "vector": "",
        "attacker": "",
        "product": "Linux kernel",
        "version": "",
        "component": "drm/xe/hmm"
    }
}
