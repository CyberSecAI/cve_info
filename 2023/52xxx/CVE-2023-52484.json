{
    "cveId": "CVE-2023-52484",
    "version": "1.0.0",
    "timestamp": "2024-12-19T22:22:49.126128+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolvediommu/arm-smmu-v3 Fix soft lockup triggered by arm_smmu_mm_invalidate_rangeWhen running an SVA case, the following soft lockup is triggered--------------------------------------------------------------------watchdog BUG soft lockup - CPU#244 stuck for 26s!pstate 83400009 (Nzcv daif +PAN -UAO +TCO +DIT -SSBS BTYPE=--)pc arm_smmu_cmdq_issue_cmdlist+0x178/0xa50lr arm_smmu_cmdq_issue_cmdlist+0x150/0xa50sp ffff8000d83ef290x29 ffff8000d83ef290 x28 000000003b9aca00 x27 0000000000000000x26 ffff8000d83ef3c0 x25 da86c0812194a0e8 x24 0000000000000000x23 0000000000000040 x22 ffff8000d83ef340 x21 ffff0000c63980c0x20 0000000000000001 x19 ffff0000c6398080 x18 0000000000000000x17 0000000000000000 x16 0000000000000000 x15 ffff3000b4a3bbb0x14 ffff3000b4a30888 x13 ffff3000b4a3cf60 x12 0000000000000000x11 0000000000000000 x10 0000000000000000 x9 ffffc08120e4d6bcx8 0000000000000000 x7 0000000000000000 x6 0000000000048cfax5 0000000000000000 x4 0000000000000001 x3 000000000000000ax2 0000000080000000 x1 0000000000000000 x0 0000000000000001Call trace arm_smmu_cmdq_issue_cmdlist+0x178/0xa50 __arm_smmu_tlb_inv_range+0x118/0x254 arm_smmu_tlb_inv_range_asid+0x6c/0x130 arm_smmu_mm_invalidate_range+0xa0/0xa4 __mmu_notifier_invalidate_range_end+0x88/0x120 unmap_vmas+0x194/0x1e0 unmap_region+0xb4/0x144 do_mas_align_munmap+0x290/0x490 do_mas_munmap+0xbc/0x124 __vm_munmap+0xa8/0x19c __arm64_sys_munmap+0x28/0x50 invoke_syscall+0x78/0x11c el0_svc_common.constprop.0+0x58/0x1c0 do_el0_svc+0x34/0x60 el0_svc+0x2c/0xd4 el0t_64_sync_handler+0x114/0x140 el0t_64_sync+0x1a4/0x1a8--------------------------------------------------------------------Note that since 6.6-rc1 the arm_smmu_mm_invalidate_range above is renamedto arm_smmu_mm_arch_invalidate_secondary_tlbs, yet the problem remains.The commit 06ff87bae8d3 (arm64 mm remove unused functions and variableprotoypes) fixed a similar lockup on the CPU MMU side. Yet, it can occurto SMMU too, since arm_smmu_mm_arch_invalidate_secondary_tlbs() is calledtypically next to MMU tlb flush function, e.g. tlb_flush_mmu_tlbonly { tlb_flush { __flush_tlb_range { // check MAX_TLBI_OPS } } mmu_notifier_arch_invalidate_secondary_tlbs { arm_smmu_mm_arch_invalidate_secondary_tlbs { // does not check MAX_TLBI_OPS } } }Clone a CMDQ_MAX_TLBI_OPS from the MAX_TLBI_OPS in tlbflush.h, since in anSVA case SMMU uses the CPU page table, so it makes sense to align with thetlbflush code. Then, replace per-page TLBI commands with a single per-asidTLBI command, if the request size hits this threshold.",
    "keyphrases": {
        "rootcause": "The arm_smmu_mm_invalidate_range function does not check MAX_TLBI_OPS, which can lead to a soft lockup when invalidating a large range of memory.",
        "weakness": "The arm_smmu_mm_invalidate_range function lacks a check for MAX_TLBI_OPS, allowing excessive TLB invalidation operations.",
        "impact": "A soft lockup occurs when an SVA case triggers excessive TLB invalidations.",
        "vector": "The vulnerability is triggered by running an SVA case that requires the invalidation of a large memory range.",
        "attacker": "An attacker can trigger the vulnerability by running a specially crafted SVA case.",
        "product": "Linux Kernel",
        "version": "6.6-rc1 and potentially earlier",
        "component": "iommu/arm-smmu-v3"
    }
}
