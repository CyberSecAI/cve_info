{
  "cveId": "CVE-2023-29374",
  "version": "1.0.0",
  "timestamp": "2024-12-15T20:24:27.876763+00:00",
  "description": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
  "keyphrases": {
    "rootcause": "",
    "weakness": "prompt injection",
    "impact": [
      "arbitrary code execution",
      "execute arbitrary code"
    ],
    "vector": "",
    "attacker": "",
    "product": "LangChain",
    "version": "through 0.0.131",
    "component": "LLMMathChain chain"
  },
  "mitreTechnicalImpacts": []
}