{
    "cveId": "CVE-2024-45024",
    "version": "1.0.0",
    "timestamp": "2024-12-06T11:32:07.789868+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved mm/hugetlb fix hugetlb vs. core-mm PT locking We recently made GUPs common page table walking code to also walk hugetlb VMAs without most hugetlb special-casing, preparing for the future of having less hugetlb-specific page table walking code in the codebase. Turns out that we missed one page table locking detail page table locking for hugetlb folios that are not mapped using a single PMD/PUD. Assume we have hugetlb folio that spans multiple PTEs (e.g., 64 KiB hugetlb folios on arm64 with 4 KiB base page size). GUP, as it walks the page tables, will perform a pte_offset_map_lock() to grab the PTE table lock. However, hugetlb that concurrently modifies these page tables would actually grab the mm->page_table_lock with USE_SPLIT_PTE_PTLOCKS, the locks would differ. Something similar can happen right now with hugetlb folios that span multiple PMDs when USE_SPLIT_PMD_PTLOCKS. This issue can be reproduced [1], for example triggering [ 3105.936100] ------------[ cut here ]------------ [ 3105.939323] WARNING CPU 31 PID 2732 at mm/gup.c142 try_grab_folio+0x11c/0x188 [ 3105.944634] Modules linked in [...] [ 3105.974841] CPU 31 PID 2732 Comm reproducer Not tainted 6.10.0-64.eln141.aarch64 #1 [ 3105.980406] Hardware name QEMU KVM Virtual Machine, BIOS edk2-20240524-4.fc40 05/24/2024 [ 3105.986185] pstate 60000005 (nZCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--) [ 3105.991108] pc try_grab_folio+0x",
    "keyphrases": {
        "rootcause": "Use of different locks for hugetlb and GUP page table locking",
        "weakness": "",
        "impact": "race condition",
        "vector": "",
        "attacker": "",
        "product": "Linux kernel",
        "version": "",
        "component": "mm/gup.c, mm/hugetlb"
    }
}
