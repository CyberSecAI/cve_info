{
    "cveId": "CVE-2024-26670",
    "version": "1.0.0",
    "timestamp": "2024-12-06T11:32:07.789868+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved arm64 entry fix ARM64_WORKAROUND_SPECULATIVE_UNPRIV_LOAD Currently the ARM64_WORKAROUND_SPECULATIVE_UNPRIV_LOAD workaround isnt quite right, as it is supposed to be applied after the last explicit memory access, but is immediately followed by an LDR. The ARM64_WORKAROUND_SPECULATIVE_UNPRIV_LOAD workaround is used to handle Cortex-A520 erratum 2966298 and Cortex-A510 erratum 3117295, which are described in * https//developer.arm.com/documentation/SDEN2444153/0600/?lang=en * https//developer.arm.com/documentation/SDEN1873361/1600/?lang=en In both cases the workaround is described as | If pagetable isolation is disabled, the context switch logic in the | kernel can be updated to execute the following sequence on affected | cores before exiting to EL0, and after all explicit memory accesses | | 1. A non-shareable TLBI to any context and/or address, including | unused contexts or addresses, such as a `TLBI VALE1 Xzr`. | | 2. A DSB NSH to guarantee completion of the TLBI. The important part being that the TLBI+DSB must be placed after all explicit memory accesses. Unfortunately, as-implemented, the TLBI+DSB is immediately followed by an LDR, as we have | alternative_if ARM64_WORKAROUND_SPECULATIVE_UNPRIV_LOAD | tlbivale1, xzr | dsbnsh | alternative_else_nop_endif | alternative_if_not ARM64_UNMAP_KERNEL_AT_EL0 | ldrlr, [sp, #S_LR] | addsp, sp, #PT_REGS_SIZE// restore sp | eret | alternative_el",
    "keyphrases": {
        "rootcause": "",
        "weakness": "improper workaround",
        "impact": "",
        "vector": "",
        "attacker": "",
        "product": "Linux kernel",
        "version": "",
        "component": ""
    }
}
