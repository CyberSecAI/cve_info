{
    "cveId": "CVE-2024-26832",
    "version": "1.0.0",
    "timestamp": "2024-12-06T11:32:07.789868+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved mm zswap fix missing folio cleanup in writeback race path In zswap_writeback_entry(), after we get a folio from __read_swap_cache_async(), we grab the tree lock again to check that the swap entry was not invalidated and recycled. If it was, we delete the folio we just added to the swap cache and exit. However, __read_swap_cache_async() returns the folio locked when it is newly allocated, which is always true for this path, and the folio is refd. Make sure to unlock and put the folio before returning. This was discovered by code inspection, probably because this path handles a race condition that should not happen often, and the bug would not crash the system, it will only strand the folio indefinitely.",
    "keyphrases": {
        "rootcause": "",
        "weakness": "missing folio cleanup",
        "impact": "strand the folio indefinitely",
        "vector": "",
        "attacker": "",
        "product": "Linux kernel",
        "version": "",
        "component": "mm zswap"
    }
}
