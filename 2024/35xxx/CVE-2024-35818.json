{
    "cveId": "CVE-2024-35818",
    "version": "1.0.0",
    "timestamp": "2024-12-06T11:32:07.789868+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved LoongArch Define the __io_aw() hook as mmiowb() Commit fb24ea52f78e0d595852e (drivers Remove explicit invocations of mmiowb()) remove all mmiowb() in drivers, but it says NOTE mmiowb() has only ever guaranteed ordering in conjunction with spin_unlock(). However, pairing each mmiowb() removal in this patch with the corresponding call to spin_unlock() is not at all trivial, so there is a small chance that this change may regress any drivers incorrectly relying on mmiowb() to order MMIO writes between CPUs using lock-free synchronisation. The mmio in radeon_ring_commit() is protected by a mutex rather than a spinlock, but in the mutex fastpath it behaves similar to spinlock. We can add mmiowb() calls in the radeon driver but the maintainer says he doesnt like such a workaround, and radeon is not the only example of mutex protected mmio. So we should extend the mmiowb tracking system from spinlock to mutex, and maybe other locking primitives. This is not easy and error prone, so we solve it in the architectural code, by simply defining the __io_aw() hook as mmiowb(). And we no longer need to override queued_spin_unlock() so use the generic definition. Without this, we get such an error when run glxgears on weak ordering architectures such as LoongArch radeon 00000400.0 ring 0 stalled for more than 10324msec radeon 00000400.0 ring 3 stalled for more than 10240msec radeon 00000400.0 GPU",
    "keyphrases": {
        "rootcause": "Remove explicit invocations of mmiowb() in drivers",
        "weakness": "",
        "impact": "may regress any drivers incorrectly relying on mmiowb() to order MMIO writes between CPUs using lock-free synchronisation",
        "vector": "",
        "attacker": "",
        "product": "Linux kernel",
        "version": "",
        "component": ""
    }
}
